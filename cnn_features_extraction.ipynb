{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Layer, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(real_path, fake_path):\n",
    "    # Đọc ảnh từ cả hai thư mục\n",
    "    real_image_files = sorted([os.path.join(real_path, f) for f in os.listdir(real_path) if f.endswith('.png')])\n",
    "    fake_image_files = sorted([os.path.join(fake_path, f) for f in os.listdir(fake_path) if f.endswith('.png')])\n",
    "\n",
    "    # Gộp ảnh từ cả hai thư mục vào một danh sách duy nhất\n",
    "    all_image_files = real_image_files + fake_image_files\n",
    "\n",
    "    # Tạo nhãn tương ứng cho ảnh (0 cho real, 1 cho fake)\n",
    "    all_labels = [0] * len(real_image_files) + [1] * len(fake_image_files)\n",
    "\n",
    "    return all_image_files, all_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path, image_size):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, image_size)\n",
    "    img = img / 255.0  \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_batch(batch_size, all_image_files, all_labels, image_size):\n",
    "    num_batch = len(all_image_files) // batch_size\n",
    "\n",
    "    batches = []\n",
    "\n",
    "    for i in range(num_batch):\n",
    "\n",
    "        batch_files = all_image_files[i * batch_size:(i + 1) * batch_size]\n",
    "        batch_labels = all_labels[i * batch_size:(i + 1) * batch_size]\n",
    "        \n",
    "        for image in batch_files:\n",
    "            batch_images = load_and_preprocess_image(image, image_size)\n",
    "            batch_images = np.stack(batch_images, axis=0)\n",
    "        \n",
    "        batch_labels = np.array(batch_labels)\n",
    "\n",
    "        batches.append((batch_images, batch_labels))\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet50 model\n",
    "def extract_features(image_size, batches):\n",
    "    #using resnet50 with imagenet weight\n",
    "    extract_model = ResNet50(\n",
    "        weights = 'imagenet',\n",
    "        include_top = False,\n",
    "        input_shape = image_size\n",
    "    )\n",
    "\n",
    "    output = extract_model.output\n",
    "    output = MaxPooling2D()(output)\n",
    "    output = Flatten()(output)\n",
    "\n",
    "    model = Model(inputs=extract_model.input, outputs=output)\n",
    "\n",
    "    #extract_feature\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for batch_images, batch_labels in batches:\n",
    "        # Extract features using ResNet50\n",
    "        batch_features = model.predict(batch_images)\n",
    "        features.append(batch_features)\n",
    "        labels.append(batch_labels)\n",
    "    \n",
    "    features = np.vstack(features)\n",
    "    labels = np.hstack(labels)\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(real_path, fake_path):\n",
    "    all_image_files, all_labels = read_img(real_path, fake_path)\n",
    "    batches = img_to_batch(batch_size=16, all_image_files=all_image_files, all_labels=all_labels, image_size=(64, 64))\n",
    "    features, labels = extract_features(image_size=(64, 64, 3), batches=batches)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 64, 64, 3), found shape=(32, 64, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mcombine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mSum24\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDPL\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDatasets\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mFake\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mSum24\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDPL\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDatasets\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mReal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[61], line 4\u001b[0m, in \u001b[0;36mcombine\u001b[1;34m(real_path, fake_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m all_image_files, all_labels \u001b[38;5;241m=\u001b[39m read_img(real_path, fake_path)\n\u001b[0;32m      3\u001b[0m batches \u001b[38;5;241m=\u001b[39m img_to_batch(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, all_image_files\u001b[38;5;241m=\u001b[39mall_image_files, all_labels\u001b[38;5;241m=\u001b[39mall_labels, image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m features, labels \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features, labels\n",
      "Cell \u001b[1;32mIn[60], line 22\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(image_size, batches)\u001b[0m\n\u001b[0;32m     18\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_images, batch_labels \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Extract features using ResNet50\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     batch_features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(batch_features)\n\u001b[0;32m     24\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(batch_labels)\n",
      "File \u001b[1;32md:\\Sum24\\DPL\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Sum24\\DPL\\.venv\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 64, 64, 3), found shape=(32, 64, 3)"
     ]
    }
   ],
   "source": [
    "features = combine(r'D:\\Sum24\\DPL\\Datasets\\Fake', r'D:\\Sum24\\DPL\\Datasets\\Real')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
