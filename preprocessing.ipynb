{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import mtcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(r\"C:\\Users\\Lenovo\\Downloads\\01_02__outside_talking_still_laughing__YVGY8LOK.mp4\\01_02__outside_talking_still_laughing__YVGY8LOK.mp4\", r'D:\\Sum24\\DPL\\Datasets\\...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_frames(video_path, path_output_dir):\n",
    "    # extract frames from a video and save to directory as 'x.png' where \n",
    "    # x is the frame index\n",
    "    if os.path.isdir(video_path):\n",
    "        video_files = [os.path.join(video_path, f) for f in os.listdir(video_path)]\n",
    "    else:\n",
    "        video_files = [video_path]\n",
    "\n",
    "    count_image = 0\n",
    "    for video in video_files:\n",
    "        vidcap = cv2.VideoCapture(video)\n",
    "\n",
    "        #tinh toan so frame moi giay\n",
    "        fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_skip = int(fps)\n",
    "\n",
    "        count = 0\n",
    "        frame_count = 0\n",
    "\n",
    "        while vidcap.isOpened():\n",
    "            ret, image = vidcap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_count % frame_skip == 0 and count <= 16:\n",
    "                # Convert frame to grayscale for face detection\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detect faces in the grayscale frame\n",
    "                face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "                faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "                largest_face = None\n",
    "                largest_area = 0\n",
    "\n",
    "                for (x, y, w, h) in faces:\n",
    "                    if w * h > largest_area:\n",
    "                        largest_area = w * h\n",
    "                        largest_face = (x, y, w, h)\n",
    "                if largest_face is not None:\n",
    "                    x, y, w, h = largest_face\n",
    "\n",
    "                # Save frames containing detected faces\n",
    "                for (x, y, w, h) in faces:\n",
    "                    face_img = image[y:y+h, x:x+w]\n",
    "                    cv2.imwrite(os.path.join(path_output_dir, '%d.png') % count, face_img)\n",
    "                    count_image += 1\n",
    "\n",
    "                count += 1\n",
    "            \n",
    "            frame_count += 1\n",
    "\n",
    "        vidcap.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def crop_image(source_dir, dest_dir):\n",
    "#     if os.path.isdir(dest_dir)==False:\n",
    "#         os.mkdir(dest_dir)\n",
    "#     detector = mtcnn.MTCNN()\n",
    "#     source_list=os.listdir(source_dir)\n",
    "#     uncropped_file_list=[]\n",
    "#     for f in source_list:\n",
    "#         f_path=os.path.join(source_dir, f)\n",
    "#         dest_path=os.path.join(dest_dir,f)\n",
    "#         img=cv2.imread(f_path)\n",
    "#         data=detector.detect_faces(img)\n",
    "#         if data ==[]:\n",
    "#             uncropped_file_list.append(f_path)\n",
    "#         else:\n",
    "#             for i, faces in enumerate(data): # iterate through all the faces found\n",
    "#                 box=faces['box']  # get the box for each face                \n",
    "#                 biggest=0                    \n",
    "#                 area = box[3]  * box[2]\n",
    "#                 if area>biggest:\n",
    "#                     biggest=area\n",
    "#                     bbox=box \n",
    "#             bbox[0]= 0 if bbox[0]<0 else bbox[0]\n",
    "#             bbox[1]= 0 if bbox[1]<0 else bbox[1]\n",
    "#             img=img[bbox[1]: bbox[1]+bbox[3],bbox[0]: bbox[0]+ bbox[2]] \n",
    "#             cv2.imwrite(dest_path, img) \n",
    "       \n",
    "#     return uncropped_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_to_frames(r\"C:\\Users\\Lenovo\\Downloads\\01_02__outside_talking_still_laughing__YVGY8LOK.mp4\", r'D:\\Sum24\\DPL\\Datasets\\Fake')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
